{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "########## Generate GPT responses ##########\n",
        "\n",
        "# Install and import necessary libraries\n",
        "!pip install openai\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import base64\n",
        "from IPython.display import display, HTML\n",
        "from openai import OpenAI\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "# Set up the OpenAI API client with your API key\n",
        "client = OpenAI(api_key='**********************************')\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    encodings = ['utf-8', 'latin1', 'ISO-8859-1']\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            return pd.read_csv(file_path, encoding=encoding)\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "    raise UnicodeDecodeError(\"Could not decode file using available encodings.\")\n",
        "\n",
        "#  Generate GPT responses based on provided question, options, and text content\n",
        "def generate_response(question, options, text_content):\n",
        "    options_str = '\\n'.join([f\"{i+1}. {option}\" for i, option in enumerate(options)])\n",
        "\n",
        "    # Query 1: Ask the GPT model to select the correct answer with an explanation\n",
        "    messages1 = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a specialist clinician. The data provided is about one patient, and it might involve a rare disease, so consider many possibilities. As a clinician, you must make data-based decisions, highly recommended to be based on journals and medical textbooks. Examination findings are very important!\"},\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": f\"Question: {question}\\n\\nOptions:\\n{options_str}\\n\\nText Content: {text_content}\"}\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    response1 = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo\",\n",
        "        seed=1234,\n",
        "        temperature = 0.1,\n",
        "        messages=messages1,\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    # Query 2:  Ask the GPT model to format the response as a list of probabilities for each option\n",
        "    messages2 = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a data organizer. Read the answer statement carefully.\"},\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": f\"Question: {question}\\n\\nOptions:\\n{options_str}\\n\\nAnswer: {response1}\\n\\n According to the answer statement, please write 100 for only one option that is expected to be the correct answer and write 0 for the others. For example: 0, 100, 0, 0. Ensure that the total has to be 100%. NEVER include additional texts.\"}\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    response2 = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo\",\n",
        "        seed=1234,\n",
        "        temperature = 0.1,\n",
        "        messages=messages2,\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    return response2.choices[0].message.content.strip()\n",
        "\n",
        "# Parse response and check percentage values\n",
        "def parse_response(response_text, num_options):\n",
        "    try:\n",
        "        percentages = [float(p.strip()) for p in response_text.split(',')]\n",
        "    except ValueError:\n",
        "        return []\n",
        "\n",
        "    total_percentage = sum(percentages)\n",
        "    return [p / total_percentage * 100 for p in percentages] if total_percentage > 0 else []\n",
        "\n",
        "# Process individual folders containing text and csv\n",
        "def process_folder(folder_path):\n",
        "    text_file = None\n",
        "    csv_file = None\n",
        "\n",
        "    # Iterate over all files in the folder\n",
        "    for file in folder_path.iterdir():\n",
        "        if file.suffix == '.txt':\n",
        "            text_file = file\n",
        "        elif file.suffix == '.csv':\n",
        "            csv_file = file\n",
        "\n",
        "    if not csv_file or not text_file:\n",
        "        return\n",
        "\n",
        "    text_content = read_text_file(text_file)\n",
        "    df = read_csv_file(csv_file)\n",
        "    question = df.columns[0]\n",
        "    options = df.iloc[:, 0].dropna().tolist()\n",
        "    response_text = generate_response(question, options, text_content)\n",
        "    percentages = parse_response(response_text, len(options))\n",
        "\n",
        "    # Update or add 'Percentages' column with response values\n",
        "    if 'Percentages' not in df.columns:\n",
        "        df['Percentages'] = pd.Series(dtype='object')\n",
        "\n",
        "    if percentages:\n",
        "        for i, percentage in enumerate(percentages):\n",
        "            if i < len(df):\n",
        "                df.at[i, 'Percentages'] = f\"{percentage:.2f}%\"\n",
        "            else:\n",
        "                new_row = [None] * len(df.columns)\n",
        "                df.loc[len(df)] = new_row\n",
        "                df.at[len(df)-1, 'Percentages'] = f\"{percentage:.2f}%\"\n",
        "    else:\n",
        "        print(\"No valid percentages returned by the API.\")\n",
        "        print(folder_path)\n",
        "\n",
        "    # Save updated DataFrame to output.csv\n",
        "    output_path = folder_path / \"output.csv\"\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "# Process ZIP file and save results in a new ZIP file\n",
        "def process_zip(zip_path, output_zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"temp_extracted\")\n",
        "\n",
        "    extracted_folder = Path(\"temp_extracted\")\n",
        "    for folder in extracted_folder.iterdir():\n",
        "        if folder.is_dir():\n",
        "            process_folder(folder)\n",
        "\n",
        "    with zipfile.ZipFile(output_zip_path, 'w') as zip_out:\n",
        "        for folder in extracted_folder.iterdir():\n",
        "            if folder.is_dir():\n",
        "                output_csv = folder / \"output.csv\"\n",
        "                if output_csv.exists():\n",
        "                    zip_out.write(output_csv, output_csv.relative_to(extracted_folder))\n",
        "\n",
        "    shutil.rmtree(\"temp_extracted\")\n",
        "\n",
        "# Upload zip, process, and download results\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    process_zip(filename, \"output.zip\")\n",
        "files.download(\"output.zip\")"
      ],
      "metadata": {
        "id": "RWa66IXFZEsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## Analyze answers of Human Experts and GPT ##########\n",
        "\n",
        "# Import necessary libraries\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Calculate accuracy ratios based on model outputs\n",
        "def calculate_ratios(output_folder):\n",
        "    summary_data = []\n",
        "    correct_count_people = 0\n",
        "    correct_count_chat = 0\n",
        "    total_files = 0\n",
        "    nan_percentage_files = 0\n",
        "\n",
        "    # Iterate over each \"output.csv\" file in the output folder\n",
        "    for file in output_folder.glob('**/output.csv'):\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "        # Check required columns and process percentage columns\n",
        "        if 'Unnamed: 2' in df.columns and 'Percentages' in df.columns and 'Unnamed: 1' in df.columns:\n",
        "            df['Unnamed: 1'] = df['Unnamed: 1'].astype(str).str.rstrip('%').astype('float')\n",
        "            df['Percentages'] = df['Percentages'].astype(str).str.rstrip('%').astype('float')\n",
        "\n",
        "            # Track files where 'Percentages' column is all NaN\n",
        "            if df['Percentages'].isna().all():\n",
        "                nan_percentage_files += 1\n",
        "                print(f\"File with all NaN 'Percentages' column: {file}\")\n",
        "\n",
        "            # Determine the answer selected by human experts based on maximum percentage\n",
        "            df['Answer_people'] = 0\n",
        "            if not df['Unnamed: 1'].isna().all():\n",
        "                max_value_people = df['Unnamed: 1'].max()\n",
        "                df.loc[df['Unnamed: 1'] == max_value_people, 'Answer_people'] = 1\n",
        "\n",
        "            # Determine the answer selected by GPT based on maximum percentage\n",
        "            df['Answer_chat'] = 0\n",
        "            if not df['Percentages'].isna().all():\n",
        "                max_value_chat = df['Percentages'].max()\n",
        "                df.loc[df['Percentages'] == max_value_chat, 'Answer_chat'] = 1\n",
        "\n",
        "            # Check if the human experts' selected answer matches the correct answer\n",
        "            correct_people = 1 if df['Unnamed: 2'].equals(df['Answer_people']) else 0\n",
        "            if correct_people:\n",
        "                correct_count_people += 1\n",
        "\n",
        "            # Check if the GPT's selected answer matches the correct answer\n",
        "            correct_chat = 1 if df['Unnamed: 2'].equals(df['Answer_chat']) else 0\n",
        "            if correct_chat:\n",
        "                correct_count_chat += 1\n",
        "\n",
        "            # Append results for the current file to summary data\n",
        "            folder_name = file.parent.name\n",
        "            summary_data.append([folder_name, correct_people, correct_chat])\n",
        "            total_files += 1\n",
        "\n",
        "    # Calculate accuracy ratios for human experts and GPT\n",
        "    correct_ratio_people = correct_count_people / total_files if total_files > 0 else 0\n",
        "    correct_ratio_chat = correct_count_chat / total_files if total_files > 0 else 0\n",
        "\n",
        "    # Display and save summary results\n",
        "    print(f\"Total number of quizzes: {total_files}\")\n",
        "    print(f\"Correct Ratio (People): {correct_ratio_people:.4f}\")\n",
        "    print(f\"Correct Ratio (Chat): {correct_ratio_chat:.4f}\")\n",
        "    print(f\"Number of files with 'Percentages' column all NaN: {nan_percentage_files}\")\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_data, columns=['name', 'people', 'chat'])\n",
        "    summary_df.to_csv('summary_results.csv', index=False)\n",
        "\n",
        "# Process the uploaded ZIP file\n",
        "def process_zip(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"temp_extracted\")\n",
        "\n",
        "    extracted_folder = Path(\"temp_extracted\")\n",
        "    calculate_ratios(extracted_folder)\n",
        "    shutil.rmtree(\"temp_extracted\")\n",
        "\n",
        "# Upload ZIP file, process, and download results\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    process_zip(filename)\n",
        "files.download('summary_results.csv')"
      ],
      "metadata": {
        "id": "9FttmtPKLBGO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}